/**
 * LLM Edge Node - Messages é…ç½®æµ‹è¯•
 *
 * æµ‹è¯•ç”¨ä¾‹ï¼š
 * P0:
 * - TC-LLM-009: ç¼–è¾‘æ¶ˆæ¯å†…å®¹
 * - TC-LLM-010: é»˜è®¤æ¶ˆæ¯åˆå§‹åŒ–
 * - TC-LLM-011: æ¶ˆæ¯æŒä¹…åŒ–
 * 
 * P1:
 * - TC-LLM-012: æ·»åŠ å¤šæ¡æ¶ˆæ¯
 * - TC-LLM-013: åˆ é™¤æ¶ˆæ¯
 * - TC-LLM-014: æ¶ˆæ¯é¡ºåº
 * - TC-LLM-017: ä½¿ç”¨è¾“å…¥å˜é‡
 * - TC-LLM-019: å¤šä¸ªå˜é‡
 *
 * âš ï¸ æµ‹è¯•é‡ç‚¹ï¼š
 * - æ¶ˆæ¯æ•°ç»„æ˜¯å¦æ­£ç¡®ä¿å­˜åˆ° node.data.content
 * - æ•°æ®ç»“æ„: [{role, content}, ...]
 */

// @ts-nocheck
import React from 'react';
import { render, screen, fireEvent, waitFor } from '@testing-library/react';
import { describe, it, expect, vi, beforeEach, afterEach } from 'vitest';
import LLM from '@/components/workflow/edgesNode/edgeNodesNew/LLM';
import type { Node } from '@xyflow/react';
import type { LLMConfigNodeData } from '@/components/workflow/edgesNode/edgeNodesNew/LLM';

// Mock é…ç½®
const mocks = vi.hoisted(() => ({
  useReactFlow: vi.fn(),
  useNodesPerFlowContext: vi.fn(),
  useGetSourceTarget: vi.fn(),
  useJsonConstructUtils: vi.fn(),
  useAppSettings: vi.fn(),
}));

vi.mock('@xyflow/react', () => ({
  useReactFlow: mocks.useReactFlow,
  Handle: ({ children }: any) => <div>{children}</div>,
  Position: { Top: 'top', Right: 'right', Bottom: 'bottom', Left: 'left' },
  MarkerType: { ArrowClosed: 'arrowclosed', Arrow: 'arrow' },
}));

vi.mock('@/components/states/NodesPerFlowContext', () => ({
  useNodesPerFlowContext: mocks.useNodesPerFlowContext,
}));

vi.mock('@/components/hooks/useGetSourceTarget', () => ({
  default: mocks.useGetSourceTarget,
}));

vi.mock('@/components/hooks/useJsonConstructUtils', () => ({
  default: mocks.useJsonConstructUtils,
}));

vi.mock('@/components/states/AppSettingsContext', () => ({
  useAppSettings: mocks.useAppSettings,
}));

vi.mock('@/components/workflow/edgesNode/edgeNodesNew/components/InputOutputDisplay', () => ({
  default: () => <div data-testid='input-output-display'>InputOutputDisplay</div>,
}));

vi.mock('@/components/misc/PuppyDropDown', () => ({
  PuppyDropdown: ({ selectedValue }: any) => (
    <div data-testid='puppy-dropdown'>{selectedValue?.name || 'Select'}</div>
  ),
}));

vi.mock('@/components/workflow/components/promptEditor', () => ({
  default: ({ messages, onChange }: any) => (
    <div data-testid='prompt-editor'>
      <textarea
        data-testid='prompt-textarea'
        value={JSON.stringify(messages)}
        onChange={(e) => {
          try {
            onChange(JSON.parse(e.target.value));
          } catch (error) {
            // Invalid JSON, ignore
          }
        }}
      />
    </div>
  ),
}));

vi.mock('react-dom', async () => {
  const actual = await vi.importActual('react-dom');
  return {
    ...actual,
    createPortal: (node: any) => node,
  };
});

describe('LLM Edge Node - Messages é…ç½®', () => {
  let mockSetNodes: any;
  let mockGetNode: any;

  const createMockNode = (overrides: Partial<LLMConfigNodeData> = {}): Node<LLMConfigNodeData> => ({
    id: 'test-llm-1',
    type: 'llm',
    position: { x: 0, y: 0 },
    data: {
      looped: undefined,
      content: null,
      modelAndProvider: {
        id: 'gpt-4',
        name: 'GPT-4',
        provider: 'OpenAI',
        isLocal: false,
      },
      structured_output: false,
      base_url: '',
      max_tokens: 128000,
      ...overrides,
    },
  });

  beforeEach(() => {
    mockSetNodes = vi.fn();
    mockGetNode = vi.fn(() => createMockNode());

    mocks.useReactFlow.mockReturnValue({
      getNode: mockGetNode,
      setNodes: mockSetNodes,
      setEdges: vi.fn(),
      getNodes: vi.fn(() => [createMockNode()]),
    });

    mocks.useNodesPerFlowContext.mockReturnValue({
      isOnConnect: false,
      activatedEdge: null,
      isOnGeneratingNewNode: false,
      clearEdgeActivation: vi.fn(),
      activateEdge: vi.fn(),
      clearAll: vi.fn(),
    });

    mocks.useGetSourceTarget.mockReturnValue({
      getSourceNodeIdWithLabel: vi.fn(() => []),
      getTargetNodeIdWithLabel: vi.fn(() => []),
    });

    mocks.useJsonConstructUtils.mockReturnValue({
      streamResult: vi.fn(),
      reportError: vi.fn(),
      resetLoadingUI: vi.fn(),
    });

    mocks.useAppSettings.mockReturnValue({
      availableModels: [{
        id: 'gpt-4',
        name: 'GPT-4',
        provider: 'OpenAI',
        isLocal: false,
        active: true,
        type: 'llm',
      }],
    });
  });

  afterEach(() => {
    vi.clearAllMocks();
  });

  describe('TC-LLM-009: ç¼–è¾‘æ¶ˆæ¯å†…å®¹ (P0)', () => {
    it('ä¿®æ”¹æ¶ˆæ¯ååº”ä¿å­˜åˆ° node.data.content', async () => {
      const initialMessages = [
        { role: 'system', content: 'You are an AI' },
        { role: 'user', content: 'Answer the question' },
      ];

      const mockNode = createMockNode({ content: initialMessages as any });
      mockGetNode.mockReturnValue(mockNode);

      render(
        <LLM
          id={mockNode.id}
          type='llm'
          data={mockNode.data}
          selected={false}
          isConnectable={true}
          xPos={0}
          yPos={0}
          zIndex={0}
          dragging={false}
        />
      );

      // æ‰“å¼€èœå•
      const button = screen.getByRole('button', { name: /LLM/i });
      fireEvent.click(button);

      // ä¿®æ”¹æ¶ˆæ¯
      const textarea = screen.getByTestId('prompt-textarea');
      const newMessages = [
        { role: 'system', content: 'You are a helpful assistant' },
        { role: 'user', content: 'Help me solve this' },
      ];

      fireEvent.change(textarea, {
        target: { value: JSON.stringify(newMessages) },
      });

      await waitFor(() => {
        expect(mockSetNodes).toHaveBeenCalled();
      });

      // éªŒè¯ content æ›´æ–°
      const setNodesCall = mockSetNodes.mock.calls[mockSetNodes.mock.calls.length - 1][0];
      const updatedNodes = setNodesCall([mockNode]);
      const updatedNode = updatedNodes.find((n: any) => n.id === mockNode.id);

      expect(updatedNode.data.content).toEqual(newMessages);
    });

    it('content åº”åŒ…å« role å’Œ content å­—æ®µ', () => {
      const messages = [
        { role: 'system', content: 'System message' },
        { role: 'user', content: 'User message' },
      ];

      const mockNode = createMockNode({ content: messages as any });

      render(
        <LLM
          id={mockNode.id}
          type='llm'
          data={mockNode.data}
          selected={false}
          isConnectable={true}
          xPos={0}
          yPos={0}
          zIndex={0}
          dragging={false}
        />
      );

      messages.forEach(msg => {
        expect(msg).toHaveProperty('role');
        expect(msg).toHaveProperty('content');
        expect(['system', 'user', 'assistant']).toContain(msg.role);
      });
    });
  });

  describe('TC-LLM-010: é»˜è®¤æ¶ˆæ¯åˆå§‹åŒ– (P0)', () => {
    it('æ–°èŠ‚ç‚¹åº”æœ‰é»˜è®¤æ¶ˆæ¯', () => {
      const mockNode = createMockNode({ content: null });
      mockGetNode.mockReturnValue(mockNode);

      render(
        <LLM
          id={mockNode.id}
          type='llm'
          data={mockNode.data}
          selected={false}
          isConnectable={true}
          xPos={0}
          yPos={0}
          zIndex={0}
          dragging={false}
        />
      );

      const button = screen.getByRole('button', { name: /LLM/i });
      fireEvent.click(button);

      // ç»„ä»¶ä¼šåˆå§‹åŒ– contentï¼ŒéªŒè¯ setNodes è¢«è°ƒç”¨
      waitFor(() => {
        const calls = mockSetNodes.mock.calls;
        if (calls.length > 0) {
          const lastCall = calls[calls.length - 1][0];
          const updatedNodes = lastCall([mockNode]);
          const updatedNode = updatedNodes.find((n: any) => n.id === mockNode.id);

          expect(Array.isArray(updatedNode.data.content)).toBe(true);
          expect(updatedNode.data.content.length).toBeGreaterThan(0);
        }
      });
    });

    it('é»˜è®¤åº”åŒ…å« system å’Œ user æ¶ˆæ¯', () => {
      const mockNode = createMockNode({
        content: [
          { role: 'system', content: 'You are an AI' },
          { role: 'user', content: 'Answer the question' },
        ] as any,
      });

      render(
        <LLM
          id={mockNode.id}
          type='llm'
          data={mockNode.data}
          selected={false}
          isConnectable={true}
          xPos={0}
          yPos={0}
          zIndex={0}
          dragging={false}
        />
      );

      const content = mockNode.data.content as any[];
      expect(content.some((msg: any) => msg.role === 'system')).toBe(true);
      expect(content.some((msg: any) => msg.role === 'user')).toBe(true);
    });
  });

  describe('TC-LLM-011: æ¶ˆæ¯æŒä¹…åŒ– (P0)', () => {
    it('å·²ä¿å­˜çš„æ¶ˆæ¯åº”æ­£ç¡®æ¢å¤', () => {
      const savedMessages = [
        { role: 'system', content: 'Custom system prompt' },
        { role: 'user', content: 'Custom user prompt' },
        { role: 'assistant', content: 'Custom assistant response' },
      ];

      const mockNode = createMockNode({ content: savedMessages as any });
      mockGetNode.mockReturnValue(mockNode);

      render(
        <LLM
          id={mockNode.id}
          type='llm'
          data={mockNode.data}
          selected={false}
          isConnectable={true}
          xPos={0}
          yPos={0}
          zIndex={0}
          dragging={false}
        />
      );

      const button = screen.getByRole('button', { name: /LLM/i });
      fireEvent.click(button);

      const textarea = screen.getByTestId('prompt-textarea');
      const displayedMessages = JSON.parse(textarea.value);

      expect(displayedMessages).toEqual(savedMessages);
    });

    it('æ¶ˆæ¯é¡ºåºåº”ä¿æŒä¸€è‡´', () => {
      const messages = [
        { role: 'system', content: 'First' },
        { role: 'user', content: 'Second' },
        { role: 'assistant', content: 'Third' },
      ];

      const mockNode = createMockNode({ content: messages as any });

      render(
        <LLM
          id={mockNode.id}
          type='llm'
          data={mockNode.data}
          selected={false}
          isConnectable={true}
          xPos={0}
          yPos={0}
          zIndex={0}
          dragging={false}
        />
      );

      const content = mockNode.data.content as any[];
      expect(content[0].content).toBe('First');
      expect(content[1].content).toBe('Second');
      expect(content[2].content).toBe('Third');
    });
  });

  describe('TC-LLM-012: æ·»åŠ å¤šæ¡æ¶ˆæ¯ (P1)', () => {
    it('åº”æ”¯æŒå¤šæ¡æ¶ˆæ¯ä¿å­˜', async () => {
      const mockNode = createMockNode();
      mockGetNode.mockReturnValue(mockNode);

      render(
        <LLM
          id={mockNode.id}
          type='llm'
          data={mockNode.data}
          selected={false}
          isConnectable={true}
          xPos={0}
          yPos={0}
          zIndex={0}
          dragging={false}
        />
      );

      const button = screen.getByRole('button', { name: /LLM/i });
      fireEvent.click(button);

      const textarea = screen.getByTestId('prompt-textarea');
      const multiMessages = [
        { role: 'system', content: 'System 1' },
        { role: 'system', content: 'System 2' },
        { role: 'user', content: 'User 1' },
        { role: 'assistant', content: 'Assistant 1' },
        { role: 'user', content: 'User 2' },
      ];

      fireEvent.change(textarea, {
        target: { value: JSON.stringify(multiMessages) },
      });

      await waitFor(() => {
        const setNodesCall = mockSetNodes.mock.calls[mockSetNodes.mock.calls.length - 1][0];
        const updatedNodes = setNodesCall([mockNode]);
        const updatedNode = updatedNodes.find((n: any) => n.id === mockNode.id);

        expect(updatedNode.data.content).toHaveLength(5);
        expect(updatedNode.data.content).toEqual(multiMessages);
      });
    });
  });

  describe('TC-LLM-013: åˆ é™¤æ¶ˆæ¯ (P1)', () => {
    it('åˆ é™¤æ¶ˆæ¯åæ•°ç»„åº”æ›´æ–°', async () => {
      const initialMessages = [
        { role: 'system', content: 'System' },
        { role: 'user', content: 'User' },
        { role: 'assistant', content: 'Assistant' },
      ];

      const mockNode = createMockNode({ content: initialMessages as any });
      mockGetNode.mockReturnValue(mockNode);

      render(
        <LLM
          id={mockNode.id}
          type='llm'
          data={mockNode.data}
          selected={false}
          isConnectable={true}
          xPos={0}
          yPos={0}
          zIndex={0}
          dragging={false}
        />
      );

      const button = screen.getByRole('button', { name: /LLM/i });
      fireEvent.click(button);

      const textarea = screen.getByTestId('prompt-textarea');
      // åˆ é™¤ä¸­é—´çš„ user æ¶ˆæ¯
      const updatedMessages = [
        { role: 'system', content: 'System' },
        { role: 'assistant', content: 'Assistant' },
      ];

      fireEvent.change(textarea, {
        target: { value: JSON.stringify(updatedMessages) },
      });

      await waitFor(() => {
        const setNodesCall = mockSetNodes.mock.calls[mockSetNodes.mock.calls.length - 1][0];
        const updatedNodes = setNodesCall([mockNode]);
        const updatedNode = updatedNodes.find((n: any) => n.id === mockNode.id);

        expect(updatedNode.data.content).toHaveLength(2);
        expect(updatedNode.data.content).toEqual(updatedMessages);
      });
    });
  });

  describe('TC-LLM-014: æ¶ˆæ¯é¡ºåº (P1)', () => {
    it('è°ƒæ•´é¡ºåºååº”æ­£ç¡®ä¿å­˜', async () => {
      const initialMessages = [
        { role: 'user', content: 'A' },
        { role: 'user', content: 'B' },
        { role: 'user', content: 'C' },
      ];

      const mockNode = createMockNode({ content: initialMessages as any });
      mockGetNode.mockReturnValue(mockNode);

      render(
        <LLM
          id={mockNode.id}
          type='llm'
          data={mockNode.data}
          selected={false}
          isConnectable={true}
          xPos={0}
          yPos={0}
          zIndex={0}
          dragging={false}
        />
      );

      const button = screen.getByRole('button', { name: /LLM/i });
      fireEvent.click(button);

      const textarea = screen.getByTestId('prompt-textarea');
      // è°ƒæ•´é¡ºåº
      const reorderedMessages = [
        { role: 'user', content: 'C' },
        { role: 'user', content: 'A' },
        { role: 'user', content: 'B' },
      ];

      fireEvent.change(textarea, {
        target: { value: JSON.stringify(reorderedMessages) },
      });

      await waitFor(() => {
        const setNodesCall = mockSetNodes.mock.calls[mockSetNodes.mock.calls.length - 1][0];
        const updatedNodes = setNodesCall([mockNode]);
        const updatedNode = updatedNodes.find((n: any) => n.id === mockNode.id);

        expect(updatedNode.data.content[0].content).toBe('C');
        expect(updatedNode.data.content[1].content).toBe('A');
        expect(updatedNode.data.content[2].content).toBe('B');
      });
    });
  });

  describe('TC-LLM-017: ä½¿ç”¨è¾“å…¥å˜é‡ (P1)', () => {
    it('å˜é‡è¯­æ³•åº”ä¿å­˜åˆ° content', async () => {
      const mockNode = createMockNode();
      mockGetNode.mockReturnValue(mockNode);

      render(
        <LLM
          id={mockNode.id}
          type='llm'
          data={mockNode.data}
          selected={false}
          isConnectable={true}
          xPos={0}
          yPos={0}
          zIndex={0}
          dragging={false}
        />
      );

      const button = screen.getByRole('button', { name: /LLM/i });
      fireEvent.click(button);

      const textarea = screen.getByTestId('prompt-textarea');
      const messagesWithVariable = [
        { role: 'system', content: 'You are an AI' },
        { role: 'user', content: 'Answer: {{inputText}}' },
      ];

      fireEvent.change(textarea, {
        target: { value: JSON.stringify(messagesWithVariable) },
      });

      await waitFor(() => {
        const setNodesCall = mockSetNodes.mock.calls[mockSetNodes.mock.calls.length - 1][0];
        const updatedNodes = setNodesCall([mockNode]);
        const updatedNode = updatedNodes.find((n: any) => n.id === mockNode.id);

        expect(updatedNode.data.content[1].content).toBe('Answer: {{inputText}}');
        expect(updatedNode.data.content[1].content).toContain('{{');
        expect(updatedNode.data.content[1].content).toContain('}}');
      });
    });

    it('å˜é‡ä¸åº”è¢«è§£ææˆ–è½¬ä¹‰', async () => {
      const mockNode = createMockNode();
      mockGetNode.mockReturnValue(mockNode);

      render(
        <LLM
          id={mockNode.id}
          type='llm'
          data={mockNode.data}
          selected={false}
          isConnectable={true}
          xPos={0}
          yPos={0}
          zIndex={0}
          dragging={false}
        />
      );

      const button = screen.getByRole('button', { name: /LLM/i });
      fireEvent.click(button);

      const textarea = screen.getByTestId('prompt-textarea');
      const message = [
        { role: 'user', content: '{{var1}} and {{var2}}' },
      ];

      fireEvent.change(textarea, {
        target: { value: JSON.stringify(message) },
      });

      await waitFor(() => {
        const setNodesCall = mockSetNodes.mock.calls[mockSetNodes.mock.calls.length - 1][0];
        const updatedNodes = setNodesCall([mockNode]);
        const updatedNode = updatedNodes.find((n: any) => n.id === mockNode.id);

        // å˜é‡è¯­æ³•åº”å®Œå…¨ä¿ç•™
        expect(updatedNode.data.content[0].content).toBe('{{var1}} and {{var2}}');
      });
    });
  });

  describe('TC-LLM-019: å¤šä¸ªå˜é‡ (P1)', () => {
    it('å¤šä¸ªå˜é‡åº”ä¿æŒåŸæ ·', async () => {
      const mockNode = createMockNode();
      mockGetNode.mockReturnValue(mockNode);

      render(
        <LLM
          id={mockNode.id}
          type='llm'
          data={mockNode.data}
          selected={false}
          isConnectable={true}
          xPos={0}
          yPos={0}
          zIndex={0}
          dragging={false}
        />
      );

      const button = screen.getByRole('button', { name: /LLM/i });
      fireEvent.click(button);

      const textarea = screen.getByTestId('prompt-textarea');
      const complexMessage = [
        {
          role: 'user',
          content: 'Compare {{input1}} with {{input2}} and analyze {{input3}}',
        },
      ];

      fireEvent.change(textarea, {
        target: { value: JSON.stringify(complexMessage) },
      });

      await waitFor(() => {
        const setNodesCall = mockSetNodes.mock.calls[mockSetNodes.mock.calls.length - 1][0];
        const updatedNodes = setNodesCall([mockNode]);
        const updatedNode = updatedNodes.find((n: any) => n.id === mockNode.id);

        const content = updatedNode.data.content[0].content;
        expect(content).toContain('{{input1}}');
        expect(content).toContain('{{input2}}');
        expect(content).toContain('{{input3}}');
        // ç¡®ä¿æ²¡æœ‰è¢«åˆå¹¶
        expect(content.match(/\{\{/g)?.length).toBe(3);
      });
    });
  });
});

/**
 * ğŸ”§ æµ‹è¯•æ€»ç»“ï¼š
 *
 * âœ… å·²æµ‹è¯•ï¼ˆP0ï¼‰ï¼š
 * - TC-LLM-009: ç¼–è¾‘æ¶ˆæ¯å†…å®¹
 * - TC-LLM-010: é»˜è®¤æ¶ˆæ¯åˆå§‹åŒ–
 * - TC-LLM-011: æ¶ˆæ¯æŒä¹…åŒ–
 *
 * âœ… å·²æµ‹è¯•ï¼ˆP1ï¼‰ï¼š
 * - TC-LLM-012: æ·»åŠ å¤šæ¡æ¶ˆæ¯
 * - TC-LLM-013: åˆ é™¤æ¶ˆæ¯
 * - TC-LLM-014: æ¶ˆæ¯é¡ºåº
 * - TC-LLM-017: ä½¿ç”¨è¾“å…¥å˜é‡
 * - TC-LLM-019: å¤šä¸ªå˜é‡
 *
 * ğŸ“ è¿è¡Œå‘½ä»¤ï¼š
 *    npm run test -- LLM.messages.test.tsx
 */

