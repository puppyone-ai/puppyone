# Qllama

ç»Ÿä¸€LLMæ¥å£ï¼Œæ”¯æŒå¤šç§æ¨¡å‹æä¾›å•†ã€‚

## ç‰¹æ€§

- ğŸ¯ **ç»Ÿä¸€æ¥å£** - ä¸€å¥—APIè°ƒç”¨ä¸åŒæä¾›å•†çš„æ¨¡å‹
- ğŸš€ **ç®€å•æ˜“ç”¨** - æœ€å°‘çš„ä»£ç å³å¯å¼€å§‹ä½¿ç”¨
- ğŸ”Œ **æ’ä»¶åŒ–** - æ”¯æŒæ‰©å±•æ–°çš„æ¨¡å‹æä¾›å•†
- ğŸ”§ **èƒ½åŠ›æ£€æµ‹** - è‡ªåŠ¨æ£€æµ‹æ¨¡å‹æ”¯æŒçš„åŠŸèƒ½ï¼ˆLLMã€åµŒå…¥ç­‰ï¼‰

## å®‰è£…

```bash
pip install -e /path/to/qllama
```

æˆ–è€…ä½¿ç”¨requirements.txt:
```bash
pip install -r requirements.txt
```

## å¿«é€Ÿå¼€å§‹

```python
from qllama import Embedder, LLM

# ä½¿ç”¨LLMç”Ÿæˆæ–‡æœ¬
llm = LLM("gpt-3.5-turbo")
response = llm.generate("å‘Šè¯‰æˆ‘Pythonçš„ä¼˜ç‚¹")
print(response)

# ä½¿ç”¨åµŒå…¥æ¨¡å‹
embedder = Embedder("text-embedding-ada-002")
embeddings = embedder.embed(["Hello", "World"])
print(f"åµŒå…¥ç»´åº¦: {len(embeddings[0])}")
```

## æ”¯æŒçš„æä¾›å•†

ä½¿ç”¨æ¨¡å‹æ³¨å†Œè¡¨æŸ¥çœ‹æ”¯æŒçš„æä¾›å•†å’Œæ¨¡å‹ï¼š

```python
from qllama import Embedder, LLM, ModelRegistry

# è·å–æ‰€æœ‰æä¾›å•†
registry = ModelRegistry()
providers = registry.list_providers()
print("æ”¯æŒçš„æä¾›å•†:", providers)

# è·å–æ”¯æŒåµŒå…¥çš„æ¨¡å‹
embed_models = Embedder.list_models()
print(f"æ”¯æŒåµŒå…¥çš„æ¨¡å‹: {embed_models}")

# è·å–æ”¯æŒLLMçš„æ¨¡å‹
llm_models = LLM.list_models()
print(f"æ”¯æŒLLMçš„æ¨¡å‹: {llm_models}")
```

## API æœåŠ¡

é¡¹ç›®åŒ…å«ä¸€ä¸ªREST APIæœåŠ¡ï¼Œæ–¹ä¾¿å…¶ä»–åº”ç”¨è°ƒç”¨ï¼š

```bash
python api_server.py
```

ç„¶åè®¿é—® http://localhost:8080 æŸ¥çœ‹æ¼”ç¤ºé¡µé¢ã€‚

## æ›´å¤šç¤ºä¾‹

æŸ¥çœ‹ `examples/` ç›®å½•äº†è§£æ›´å¤šä½¿ç”¨ç¤ºä¾‹ï¼š

```python
from qllama import Embedder, LLM

# æŒ‡å®šæä¾›å•†
llm = LLM("gpt-4", provider_name="openai")
response = llm.generate("ä½ å¥½")

# è‡ªå®šä¹‰é…ç½®
embedder = Embedder("bge-large:latest", provider_name="ollama", endpoint="http://localhost:11434")
vectors = embedder.embed(["æ–‡æ¡£1", "æ–‡æ¡£2"], timeout=60)
``` 